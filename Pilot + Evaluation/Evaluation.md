### \# Core assignment: Evaluation \[+10\] Group

**Phase**: Evaluation  
**Due date**: Friday, March 14 at 11:59pm PT  
**The goal** of this stage of the project is to evaluate your high-fidelity prototype with potential users.   
**Course learning objectives** this assignment facilitates: (1) Create an interactive system grounded in user research, iterative prototyping, and evaluation; (2) Explore and express complex problems, design choices; and (3) Reflect on what you know, don’t know, and how to learn what you don’t know.   
**Grading**: This is a group assignment. All members of the group are expected to participate fully. Each group will receive one grade. / Every member will receive the same number of points.  
**What to submit**: Add a .MD file in your GitHub repo with the responses to the following questions. **Submit the github repo link to BruinLearn. Only one person needs to submit for the group.**

#### Conducting user evaluation \[+5\]

Your goal is to assess the usability of your system. 

1. \[+5\] Evaluate your system with at least 10 participants. Write and submit 0.5-1p of notes for each participant.   
2. \[+1\] DEPTH: Evaluate with 5 more participants. Feel free to make changes to your system between the first and second round of evaluation. If you do make changes, summarize the changes you made and why. 

#### After your evaluation \[+4\]

1. \[+4\] Analyze your data and write up your key findings. The findings should be about 0.5-1p for each motivating question and any other interesting findings.    
- For any qualitative data where you cannot easily remember the details of the results, a thematic analysis is required. When you conduct a thematic analysis, include your codebook.  
- For any quantitative data, submit a script for analysis \+ your data. Recommendation: Create a notebook for your analysis. Someone should be able to run your notebook to reproduce your results. 

#### Group Reflection \[+1\]

1. What is one thing that went well in your evaluation?  
2. What is one thing that you wish you could have done differently?   
3. How, if at all, did your participants represent the personas you intended to design for?   
4. How do you think this impacted your results?   
5. Based on the above, what does this say about the potential applicability of your system?  
6. What new questions do you have based on your evaluation? 

Did you use a generative AI tool for this assignment? If so, which tool(s) and how?  
How much time did you spend on this assignment as a group? individually?